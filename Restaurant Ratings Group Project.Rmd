---
title: "Restaurant Ratings Group Project"
author: "Matt"
date: "January 16, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

We explore the effect that ratings have on small and medium-sized (i.e. non-chain) restaurants in major US cities (depending on the amount of data available, we may limit analysis this to NYC). We'd use open APIs provided by Foursquare (and potentially Yelp) to access data on both reviews and check-ins (which we'd consider to be a proxy for sales). We will first look at the data before we come up with one or more crisp research questions, but we're thinking about something along the lines of the following:
 
1.     Do significant (and secular) changes in ratings affect check-ins for established restaurants?
 
       The data that we are using from foursquare consists of check-ins over a given period of time for each restaurant.
       Preparation of a treatment group: This consists of restaurants that have undergone a significant change in ratings (for e.g. a change >1) over a period of time.
        o   We run logistic regressions on this data in order to determine the predictive power of various restaurant features on the outcome of interest namely changes in check-ins.
        o   Using features that we identify as sufficiently predictive, we would conduct a propensity score matching ideally using “nearest neighbor matching”. This control group consists of restaurants that have not undergone a significant change in rating but are as similar as possible to the restaurants in the treatment group.
              ·  We would use this matched control group to ascertain the impact of the change in rating to the restaurants in the treatment group.
 
2.     To what extent does an increase (or decrease) in ratings explain the variance in check-ins? 
        ·      Perform a regression analysis (using ordered logistic regression) to determine the correlation between ratings and check-ins
 
3. For businesses with the same rating, how important is the distribution of ratings (i.e. does having a higher proportion of one-star ratings make a difference?) 
        ·      Repeat approach of Step 1. with treatment groups selected based on variance of ratings in the 90th percentile

```{r Analysis}

#uncompress data
library(foreign)
untar("C:/Users/Matthew/Downloads/yelp_dataset_challenge_round9.tar", compressed = "none", exdir ="C:/Users/Matthew/Documents")

#import data and create dataframes 
library(jsonlite)
YelpCheckins <- stream_in(file("C:/Users/Matthew/Documents/yelp_academic_dataset_checkin.json"),pagesize = 500)

YelpBusinesses <- stream_in(file("C:/Users/Matthew/Documents/yelp_academic_dataset_business.json"),pagesize = 500)

YelpReviews <- stream_in(file("C:/Users/Matthew/Documents/yelp_academic_dataset_review.json"),pagesize = 500)



#strip out businesses that aren't restaurants, have fewer than 50 reviews, or are no longer active
require(plyr)
library(tidyverse)
library(stringr)

Restaurants_v1 <- subset(YelpBusinesses,is_open == 1)
Restaurants_v2 <- filter(Restaurants_v1 , grepl('Restaurants',categories))
Restaurants_v3 <- subset(Restaurants_v2,review_count > 50)

#merge checkins data with restaurants data, matching on business_id
Restaurants_v4 <- merge(x=Restaurants_v3, y=YelpCheckins, by.x="business_id", by.y="business_id", all=TRUE)
Restaurants_v5 <- subset(Restaurants_v4,is_open == 1)

require(dplyr)
require(tidyr)
YelpCheckins

YelpCheckins %>% 
    mutate(time = strsplit(as.character(time), ",")) %>% 
    unnest(time)


Restaurants_v5 <- read.table(textConnection("1|a,b,c\n2|a,c\n3|b,d\n4|e,f"), header = F, sep = "|", stringsAsFactors = F)

s <- strsplit(as.character(Restaurants_v5$time), split = ",")
data.frame(business_id = rep(Restaurants_v5$business_id, sapply(s, length)), time = unlist(s))




#require packages for logistic regression
require(foreign)
require(nnet)
require(ggplot2)
require(reshape2)
require(MASS)
require(ResourceSelection)

#run ordered logistic regressions to assess the predictive power of rating, number of ratings, and location on restaurant checkins within the past year
CheckinsLogitModel <- polr(as.factor(checkins_count) ~ review_count + stars, data=Restaurants_v5, Hess = TRUE)
summary(CheckinsLogitModel)







#Runs logistic regression of demographic variables on Treatment Outcome Variable 
Treat <- glm(Treatment ~ as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = MasterDataSet, family = "binomial")
summary(Treat)

#runs nearest neighbor PSM
library(MatchIt)
NearestNeighborPSM <- matchit(Treatment ~ as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = FinalMatchedDataSet, method = "nearest", distance ="logit")
NearestNeighbor10PSM <- matchit(Treatment ~ as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = FinalMatchedDataSet, method = "nearest", distance ="logit",ratio=10)
NearestNeighbor30PSM <- matchit(Treatment ~ as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = FinalMatchedDataSet, method = "nearest", distance ="logit",ratio=30)

NearestNeighborPSMYearAdded <- matchit(Treatment ~ as.factor(FallYear) + as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = FinalMatchedDataSet, method = "nearest", distance ="logit")
NearestNeighbor10PSMYearAdded <- matchit(Treatment ~ as.factor(FallYear) + as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = FinalMatchedDataSet, method = "nearest", distance ="logit",ratio=10)
NearestNeighbor30PSMYearAdded <- matchit(Treatment ~ as.factor(FallYear) + as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = FinalMatchedDataSet, method = "nearest", distance ="logit",ratio=30)

NearestNeighborPSMSchoolAdded <- matchit(Treatment ~ as.factor(SchoolLEA) + as.factor(FallYear) + as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = FinalMatchedDataSet, method = "nearest", distance ="logit")
NearestNeighbor10PSMSchoolAdded <- matchit(Treatment ~ as.factor(SchoolLEA) + as.factor(FallYear) + as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = FinalMatchedDataSet, method = "nearest", distance ="logit",ratio=10)
NearestNeighbor30PSMSchoolAdded <- matchit(Treatment ~ as.factor(SchoolLEA) + as.factor(FallYear) + as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed , data = FinalMatchedDataSet, method = "nearest", distance ="logit",ratio=30)

#produces summaries
summary(NearestNeighborPSM)
library(dplyr)
match_cov <- select(m.dat, as.factor(Race_Eth) + Meal_Status_detail + Gender + Special_Ed)
MatchedDataNNPSM10 <- match.data(NearestNeighborPSM)
summary(MatchedDataNNPSM10)
as.numeric(MatchedData$GK_AC)
mean(MatchedData,GK_AC)

summary(MatchedData$GK_AC)

library(xlsx)
write.xlsx(MatchedDataNNPSM10, "C:/Users/Matt/Documents/NearestNeighbordPSM10.xlsx")


#match_cov %>% 
 # group_by( ) %>%
  #summarise_each(funs(mean))

#x0out <- sim(NearestNeighborPSM,x=)
#summary(OptimalPSM)






```

## Including Plots


```{r Visualization, echo=FALSE}

#visualize data

################################
###Presentation and Graphics###
################################

## store table
ctable <- coef(summary(GeneralKnowledgeOrderedLogitModel))

## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2

## combined table
ctable <- cbind(ctable, "p value" = p)
summary(ctable)
 
## boxplot
ggplot(CleanControlDataMerged, aes(x = GK_AC, y = Special_Ed)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) +
  facet_grid(pared ~ public, margins = TRUE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))




plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
